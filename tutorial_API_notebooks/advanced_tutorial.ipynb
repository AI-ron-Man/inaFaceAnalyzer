{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382fe905",
   "metadata": {},
   "source": [
    "# Using inaFaceAnalyzer API: advanced tutorial\n",
    "In this tutorial, define a custom analysis pipeline. This is achieved by defining 3 core parametric elements:\n",
    "* face detection\n",
    "* face classification\n",
    "* image or video processing engine\n",
    "\n",
    "Both of these processing classes are are designed as ['functions objects' or 'functors'](https://en.wikipedia.org/wiki/Function_object): instances of these objects can be used as functions, executing the code implemented in `__call__` methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402804d",
   "metadata": {},
   "source": [
    "## Install `inaFaceAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to import inaFaceAnalyzer and import it from Pypi's\n",
    "# if it is not available\n",
    "try:\n",
    "  import inaFaceAnalyzer\n",
    "except:\n",
    "  # install inaFaceAnalyzer Pypi's distribution\n",
    "  !pip install inaFaceAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359cd5a",
   "metadata": {},
   "source": [
    "## Download and display sample video\n",
    "still easy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e75e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to display videos in jupyter and collab notebooks\n",
    "from inaFaceAnalyzer.display_utils import notebook_display_local_vid\n",
    "# used to download remote files\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "\n",
    "# donwload remote file\n",
    "sample_vid = get_file('samplevid.mp4', 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/pexels-artem-podrez-5725953.mp4')\n",
    "#display local file path\n",
    "print(sample_vid)\n",
    "# display video\n",
    "notebook_display_local_vid(sample_vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec22f1a",
   "metadata": {},
   "source": [
    "## Face classification model\n",
    "`inaFaceAnalyzer` implements four face classification models.\n",
    "Both of them require eye-aligned images of isolated faces with fixed dimension (224\\*224). This face dimension size may be changed when integrating future face classifiers.\n",
    "\n",
    "Resnet50FairFaceGRA is the most accurate model, and is able to detect gender and age from face. It is used by default in processing engines. The remaining models do only detect gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all available face classifier classes listed bellow\n",
    "from inaFaceAnalyzer.face_classifier import Resnet50FairFaceGRA, Resnet50FairFace, Vggface_LSVM_FairFace, Vggface_LSVM_YTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and decode remote 224*224 preprocessed faces\n",
    "\n",
    "from inaFaceAnalyzer.opencv_utils import imread_rgb\n",
    "\n",
    "diallo_fname = get_file('diallo224.jpg', 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/diallo224.jpg')\n",
    "knuth_fname = get_file('knuth224.jpg', 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/knuth224.jpg')\n",
    "\n",
    "# open images and convert them to numpy RBG arrays\n",
    "# verbose=True allow to display the images being opened\n",
    "diallo_img = imread_rgb(diallo_fname, verbose=True)\n",
    "knuth_img = imread_rgb(knuth_fname, verbose=True)\n",
    "# print the resulting opened image as numpy array\n",
    "print(diallo_img.shape)\n",
    "print(diallo_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e043f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a classifier instance: Resnet50GairFaceGRA is the most accurate model\n",
    "c = Resnet50FairFaceGRA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b264f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_img_list method allow to process a list of preprocessed image files FAST\n",
    "# it is used when evaluating a classifer on preprocessed faces\n",
    "c.preprocessed_img_list([diallo_fname, knuth_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59174514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the same list of images with another classifier that do only predict gender\n",
    "c = Vggface_LSVM_YTF()\n",
    "c.preprocessed_img_list([diallo_fname, knuth_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e20d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When used as a functor, a classifier requires a list of opened images as first argument\n",
    "# named argument verbose is not to be used in production and allow to display the images being classified\n",
    "c([diallo_img, knuth_img], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d2e90",
   "metadata": {},
   "source": [
    "## Defining the Face Detection module\n",
    "The face detection module is in charge of finding faces in an image frame. Face detection classes return one or several bounding boxes associated to a face detection confidence.\n",
    "\n",
    "\n",
    "Two face detection classes are provided :\n",
    "* `LibFaceDetection` (default) : is the most recent face detection engine integrated. It can take advantage of GPU acceleration and is able de detect the smallest faces. It may be slow when used with high resolution images.\n",
    "* `OcvCnnFaceDetector` : is based on OpenCV CNN face detection model. Images are fist resized to 300\\*300 pixels, which may result in missing the smallest faces. It is definitely faster.\n",
    "\n",
    "\n",
    "Implemented face detection classes allow to define 4 parameters in their constructor\n",
    " * `minconf` : the minimal face detection confidence for being returned (default values dependent on the face detection class choosen).\n",
    " * `min_size_px` : minimal face size in pixels (default 30): better classification results requires face sizes above 75 pixels\n",
    " * `min_size_prct` : minimal face size as a percentage of frame minimal dimension\n",
    " * `padd_prc` : percentage of black padding pixels to be applied on images before detection (fault values are set or each detection class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec245d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all available face detection classes listed bellow\n",
    "from inaFaceAnalyzer.face_detector import LibFaceDetection, OcvCnnFacedetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9558d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and open a sample image\n",
    "india_fname = get_file('india.jpg', 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/800px-India_(236650352).jpg')\n",
    "img = imread_rgb(india_fname, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5763a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a detector instance with default parameters\n",
    "d = OcvCnnFacedetector()\n",
    "# detect faces and return Detection named tuples with fields bbox and detect_conf\n",
    "d(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use verbose=True to display detected faces\n",
    "d(img, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c05391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a detector instance that will discard faces below 100 pixels\n",
    "d = OcvCnnFacedetector(min_size_px=100)\n",
    "d(img, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7060504",
   "metadata": {},
   "source": [
    "## Defining an analysis engine\n",
    "Four analysis engine are provided : \n",
    "* `ImageAnalyzer` : which is used with image files\n",
    "* `VideoAnalyzer` : default choice to be used with video\n",
    "* `VideoKeyframes` : do only process video Keyframes\n",
    "* `VideoTracking` : perform face detection and tracking, allowing to faster computations and smooth results\n",
    "\n",
    "Engine constructors accept at least 3 optional arguments : \n",
    "* `face_detector` : instance of face detection model\n",
    "* `face_classifier` : instance of face classification model\n",
    "* `verbose` : when set to True, display intermediate images and results (not to be used in production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import here 3 different Video processing engine, and 1 image processing engine\n",
    "# both inherits from inaFaceAnalyzer.FaceAnalyzer\n",
    "from inaFaceAnalyzer.inaFaceAnalyzer import VideoAnalyzer, VideoKeyframes, VideoTracking, ImageAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate an Image Analyzer with custom face detection and face classification module\n",
    "classifier = Vggface_LSVM_FairFace()\n",
    "detector = OcvCnnFacedetector(minconf=0.5)\n",
    "ia = ImageAnalyzer(face_classifier=classifier, face_detector=detector, verbose=True)\n",
    "ia(india_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b658e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an image analyzer instance with different face classification and detection models\n",
    "detector = LibFaceDetection(minconf=0.4)\n",
    "classifier = Resnet50FairFaceGRA()\n",
    "ia = ImageAnalyzer(face_classifier=classifier, face_detector=detector, verbose=True)\n",
    "ia(india_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using video engine with verbosity\n",
    "va = VideoAnalyzer(face_classifier=Resnet50FairFaceGRA(), face_detector=OcvCnnFacedetector(), verbose=True)\n",
    "# will set FPS at 0.5, meaning 0.5 frame analyzed per second of content. ie: 1 frame every 2 seconds\n",
    "va(sample_vid, fps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db73a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we analyze 5 frames per second\n",
    "va(sample_vid, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the video keyframes engine\n",
    "# analysis based on keyframes alllow to get a fast summary of a video,\n",
    "# associated to a variable frame analysis rate\n",
    "# it cannot be used with fps argument\n",
    "va = VideoKeyframes(face_detector=LibFaceDetection(), face_classifier=Resnet50FairFaceGRA(), verbose=True)\n",
    "# the video keyframes engine is run with verbose = True allowing to show each processed frames\n",
    "# For this material, key frames coorespond to frames 0, 91, 182 and 273\n",
    "va(sample_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face tracking can be used to lower computation time and smooth prediction results\n",
    "# VideoTracking constructor require a detection period_argument, defining how often\n",
    "# the detection engine will be used\n",
    "# in this example, we analyze all frames (30 per seconds), with a detection_period = 5\n",
    "# Face detection procedure will be used 6 times per second\n",
    "#\n",
    "# Resulting dataframes have additional columns\n",
    "# * face_id: numeric identifier allowing to track previously detected faces\n",
    "# * columns with avg suffix: smoothed result\n",
    "ta = VideoTracking(detection_period=5, face_classifier=Resnet50FairFaceGRA())\n",
    "ta(sample_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d642da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
