{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1bdac7",
   "metadata": {},
   "source": [
    "# Using inaFaceAnalyzer API: a quick-start tutorial\n",
    "In this tutorial, we use inaFaceAnalyzer with default analysis parameters and export results to CSV, rich ASS subtitles and incrusted MP4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3617f",
   "metadata": {},
   "source": [
    "## Install inaFaceAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae09384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to import inaFaceAnalyzer and import it from Pypi's\n",
    "# if it is not available\n",
    "try:\n",
    "  import inaFaceAnalyzer\n",
    "except:\n",
    "  # install inaFaceAnalyzer Pypi's distribution\n",
    "  !pip install inaFaceAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72430a",
   "metadata": {},
   "source": [
    "## Define and display sample video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to display videos in jupyter and collab notebooks\n",
    "from inaFaceAnalyzer.display_utils import notebook_display_vid\n",
    "\n",
    "# input materials can be provided using file paths or remote urls\n",
    "sample_vid = 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/pexels-artem-podrez-5725953.mp4'\n",
    "# set desired width used for displaying video\n",
    "notebook_display_vid(sample_vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee66b09",
   "metadata": {},
   "source": [
    "## Analyse a video with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f623afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the video processing engine\n",
    "from inaFaceAnalyzer.inaFaceAnalyzer import VideoAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a video analyzer instance\n",
    "# classifications models may be downloaded from remote location\n",
    "# machine learning models are loaded during analyzer constructor and may require several seconds\n",
    "# consequently, users should use the same analyzer instance to process several documents\n",
    "va = VideoAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzers are designed as 'functions objects' or 'functors'\n",
    "# see https://en.wikipedia.org/wiki/Function_object\n",
    "# ie: analyzer instances can be used as functions, doing the code implemented in __call__ methods\n",
    "# this example will have \"long\" processing time since all video frames will be processed\n",
    "df = va(sample_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fe91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis results are returned as pandas DataFrames\n",
    "# see https://pandas.pydata.org/docs/\n",
    "# Results one line per detected faces and several columns : \n",
    "#\n",
    "# frame: the position of the frame in the video stream\n",
    "# bbox: (left, top, right, bottom) the bounding box of the face in the image frame\n",
    "# detect_conf: the face detection confidence estimate (dependent on the face detection method used)\n",
    "# sex_decfunc: raw gender classifier output : positive values are used for men and negative values for women\n",
    "# sex_label: gender classifer prediction: 'm' for men and 'w' for 'women'\n",
    "# age_decfunc: raw age regression output based on FairFace age categories.\n",
    "# 0 for (0-3 years old), 1 for (4-9) years, 2 for (10-19)  years, 3 for (20-29)  years, etc...\n",
    "# sex_label : \"human-readable\" age prediction\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03051497",
   "metadata": {},
   "source": [
    "## Exporting analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes are easy to export in CSV or to any tabular format\n",
    "df.to_csv('./myexport.csv')\n",
    "# display the resulting csv\n",
    "!cat myexport.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68da61",
   "metadata": {},
   "source": [
    "## Exporting results to rich subtitles\n",
    "Ass subtitles allow to display detected faces and classification results in VLC or ELAN\n",
    "Subtitles are a good option for sharing results, since they do not require a large amount of storage size, and do not alter original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602da8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inaFaceAnalyzer.display_utils import ass_subtitle_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to ass\n",
    "# requires\n",
    "# arg1 : input video filename or URL\n",
    "# arg2 : analysis result (as a pandas dataframe OR as a resulting csvfile)\n",
    "# arg3 : export ass subtitle file name\n",
    "# arg4: analysis FPS not used here\n",
    "ass_subtitle_export(sample_vid, df, './mysample.ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download video: VLC cannot display subtitles on a remote video\n",
    "!wget $sample_vid -O ./sample_vid.mp4\n",
    "# open original video with the subtitle file in VLC (cannot be done in google collab)\n",
    "!vlc --sub-file ./mysample.ass ./sample_vid.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c5c50",
   "metadata": {},
   "source": [
    "## Exporting results to incrusted MP4 Videos\n",
    "We provide result export options to MP4\n",
    "MP4 export is slow and generate large files, we recommed using ASS subtitle export when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inaFaceAnalyzer.display_utils import video_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f55a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to MP4\n",
    "# requires\n",
    "# arg1 : input video filename or URL\n",
    "# arg2 : analysis result (as a pandas dataframe OR as a resulting csvfile)\n",
    "# arg3 : resulting incrusted MP4 file name\n",
    "# arg4: analysis FPS not used here\n",
    "video_export(sample_vid, df, './myexportedvid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_display_vid(\"./myexportedvid.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36998fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
