{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382fe905",
   "metadata": {},
   "source": [
    "# Using inaFaceAnalyzer API: a video analysis quick-start tutorial\n",
    "In this tutorial, we use inaFaceAnalyzer with default analysis parameters and export results to CSV, rich ASS subtitles and incrusted MP4. We also introduce FPS runtime argument allowing to speed-up analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402804d",
   "metadata": {},
   "source": [
    "## Install inaFaceAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to import inaFaceAnalyzer and import it from Pypi's\n",
    "# if it is not available\n",
    "try:\n",
    "  import inaFaceAnalyzer\n",
    "except:\n",
    "  # install inaFaceAnalyzer Pypi's distribution\n",
    "  !pip install inaFaceAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359cd5a",
   "metadata": {},
   "source": [
    "## Define and display sample video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e75e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to display videos in jupyter and collab notebooks\n",
    "from inaFaceAnalyzer.notebook_utils import notebook_display_remote_vid, notebook_display_local_vid\n",
    "\n",
    "# input materials can be provided using file paths or remote urls\n",
    "sample_vid = 'https://github.com/ina-foss/inaFaceAnalyzer/raw/master/media/pexels-artem-podrez-5725953.mp4'\n",
    "# set desired width used for displaying video\n",
    "notebook_display_remote_vid(sample_vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec22f1a",
   "metadata": {},
   "source": [
    "## Analyse a video with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the video processing engine\n",
    "from inaFaceAnalyzer.inaFaceAnalyzer import VideoAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a video analyzer instance\n",
    "# Required classifications and detection models are first downloaded from remote location\n",
    "# machine learning models loading is done during analyzer constructor and may require several seconds\n",
    "# consequently, users should use the same analyzer instance to process several documents\n",
    "#\n",
    "# Analyzer's constructor may accept several parameters allowing\n",
    "# to customize the processings to be done\n",
    "# These parameters will be covered in more advanced tutorials\n",
    "va = VideoAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzers are designed as 'functions objects' or 'functors'\n",
    "# see https://en.wikipedia.org/wiki/Function_object\n",
    "# ie: analyzer instances can be used as functions, executing the code implemented in __call__ methods\n",
    "# this example will have \"long\" processing time since all video frames will be processed\n",
    "df = va(sample_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis results are returned as pandas DataFrames\n",
    "# see https://pandas.pydata.org/docs/\n",
    "# Results contain one line per detected faces and several columns :\n",
    "#\n",
    "# frame: the position of the frame in the video stream\n",
    "# bbox: (left, top, right, bottom) the bounding box of the face in the image frame\n",
    "# detect_conf: the face detection confidence estimate (dependent on the face detection method used)\n",
    "# sex_decfunc: raw gender classifier output : positive values are used for men and negative values for women\n",
    "# sex_label: gender classifer prediction: 'm' for men and 'w' for 'women'\n",
    "# age_decfunc: raw age regression output based on FairFace age categories.\n",
    "# 0 for (0-3 years old), 1 for (4-9) years, 2 for (10-19)  years, 3 for (20-29)  years, etc...\n",
    "# sex_label : \"human-readable\" age prediction\n",
    "#\n",
    "# In this example, we found 1313 faces in a 12 second video sampled at 30 FPS\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377f832",
   "metadata": {},
   "source": [
    "## Faster analyses with FPS argument\n",
    "In the previous example, we performed face detection and classification for each video frames, using a video containing 30 frames per seconds.\n",
    "While this strategy provide the most robust results, it is **SLOW** and not suited to large-scale processing.\n",
    "`inaFaceAnalyzer` allow to define `fps` argument: the amount of frames to be processed of each second of video.\n",
    "This allows users to define proper trade-offs between the amount of data to process and the available computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define fps=2 in order to process only 2 frames for each second of video\n",
    "# this is faster\n",
    "ANALYSIS_FPS = 2\n",
    "df_fps2 = va(sample_vid, fps=ANALYSIS_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when analysing only 2 frames per second of video, process only\n",
    "# 24 images instead of 345, and we find 89 faces (instead of 1313)\n",
    "# in the current 12 second except of video\n",
    "df_fps2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aeb9c3",
   "metadata": {},
   "source": [
    "## Exporting analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes are easy to export in CSV or to any tabular format\n",
    "df.to_csv('./myexport.csv')\n",
    "# display the resulting csv\n",
    "!cat myexport.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f486d",
   "metadata": {},
   "source": [
    "## Exporting results to rich subtitles\n",
    "Ass subtitles allow to display detected faces and classification results in VLC or ELAN\n",
    "Subtitles are a good option for sharing results, since they do not require a large amount of storage size, and do not alter original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inaFaceAnalyzer.display_utils import ass_subtitle_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to ass\n",
    "# requires\n",
    "# arg1 : input video filename or URL\n",
    "# arg2 : analysis result (as a pandas dataframe OR as a resulting csvfile)\n",
    "# arg3 : export ass subtitle file name\n",
    "# arg4: analysis FPS not used with default FPS parameters\n",
    "ass_subtitle_export(sample_vid, df, './mysample.ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83070293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download video: VLC cannot display subtitles on a remote video\n",
    "!wget $sample_vid -O ./sample_vid.mp4\n",
    "# open original video with the subtitle file in VLC (cannot be done in google collab)\n",
    "!vlc --sub-file ./mysample.ass ./sample_vid.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ass subtitles for results obtained with analysis FPS = 2\n",
    "# When exporting results that were obtained with fps option,\n",
    "# you should provide the value of analysis FPS that was used\n",
    "ass_subtitle_export(sample_vid, df_fps2, './mysample_FPS2.ass', ANALYSIS_FPS)\n",
    "!vlc --sub-file ./mysample_FPS2.ass ./sample_vid.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d4904",
   "metadata": {},
   "source": [
    "## Exporting results to incrusted MP4 Videos\n",
    "We provide result export options to MP4\n",
    "MP4 export is slow and generate large files, we recommed using ASS subtitle export when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inaFaceAnalyzer.display_utils import video_export\n",
    "from inaFaceAnalyzer.notebook_utils import notebook_display_local_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ea72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to MP4\n",
    "# requires\n",
    "# arg1 : input video filename or URL\n",
    "# arg2 : analysis result (as a pandas dataframe OR as a resulting csvfile)\n",
    "# arg3 : resulting incrusted MP4 file name\n",
    "# arg4: analysis FPS not used with default analysis option\n",
    "video_export(sample_vid, df, './myexportedvid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26045d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_display_local_vid(\"./myexportedvid.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export incrusted MP4 for results obtained with analysis FPS = 2\n",
    "# Resulting MP4 will also contain 2 Frames per second\n",
    "# When exporting results that were obtained with fps option,\n",
    "# you should provide the value of analysis FPS that was used\n",
    "video_export(sample_vid, df_fps2, './myexportedvid_fps2.mp4', ANALYSIS_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d895094",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_display_local_vid(\"./myexportedvid_fps2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d642da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
